{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPOEkMfvDH8g",
        "outputId": "ce534d7c-85d8-4737-dbc9-c12f2950fde7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_tf_matrix(freq_matrix):\n",
        "    tf_matrix = {}\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        tf_table = {}\n",
        "\n",
        "        count_words_in_sentence = len(f_table)\n",
        "        for word, count in f_table.items():\n",
        "            tf_table[word] = count / count_words_in_sentence\n",
        "\n",
        "        tf_matrix[sent] = tf_table\n",
        "\n",
        "    return tf_matrix"
      ],
      "metadata": {
        "id": "NavoNUhseKXS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
        "    idf_matrix = {}\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        idf_table = {}\n",
        "\n",
        "        for word in f_table.keys():\n",
        "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
        "\n",
        "        idf_matrix[sent] = idf_table\n",
        "\n",
        "    return idf_matrix"
      ],
      "metadata": {
        "id": "c3Usrcxce37s"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
        "    tf_idf_matrix = {}\n",
        "\n",
        "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
        "\n",
        "        tf_idf_table = {}\n",
        "\n",
        "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
        "                                                    f_table2.items()):  # here, keys are the same in both the table\n",
        "            tf_idf_table[word1] = float(value1 * value2)\n",
        "\n",
        "        tf_idf_matrix[sent1] = tf_idf_table\n",
        "\n",
        "    return tf_idf_matrix"
      ],
      "metadata": {
        "id": "WbK1LLEke6hq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def _create_frequency_matrix(sentences):\n",
        "    frequency_matrix = {}\n",
        "    stopWords = set(stopwords.words(\"english\"))\n",
        "    ps = PorterStemmer()\n",
        "\n",
        "    for sent in sentences:\n",
        "        freq_table = {}\n",
        "        words = word_tokenize(sent)\n",
        "        for word in words:\n",
        "            word = word.lower()\n",
        "            word = ps.stem(word)\n",
        "            if word in stopWords:\n",
        "                continue\n",
        "\n",
        "            if word in freq_table:\n",
        "                freq_table[word] += 1\n",
        "            else:\n",
        "                freq_table[word] = 1\n",
        "\n",
        "        frequency_matrix[sent[:15]] = freq_table\n",
        "\n",
        "    return frequency_matrix"
      ],
      "metadata": {
        "id": "lQVvUPhWlony"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_documents_per_words(freq_matrix):\n",
        "    word_per_doc_table = {}\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        for word, count in f_table.items():\n",
        "            if word in word_per_doc_table:\n",
        "                word_per_doc_table[word] += 1\n",
        "            else:\n",
        "                word_per_doc_table[word] = 1\n",
        "\n",
        "    return word_per_doc_table"
      ],
      "metadata": {
        "id": "_-ZjwcREeMyE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def _score_sentences(tf_idf_matrix) -> dict:\n",
        "    \"\"\"\n",
        "    score a sentence by its word's TF\n",
        "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "\n",
        "    sentenceValue = {}\n",
        "\n",
        "    for sent, f_table in tf_idf_matrix.items():\n",
        "        total_score_per_sentence = 0\n",
        "\n",
        "        count_words_in_sentence = len(f_table)\n",
        "        for word, score in f_table.items():\n",
        "            total_score_per_sentence += score\n",
        "\n",
        "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
        "\n",
        "    return sentenceValue"
      ],
      "metadata": {
        "id": "z3wkgkJllP2y"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _score_sentences(tf_idf_matrix) -> dict:\n",
        "    \"\"\"\n",
        "    score a sentence by its word's TF\n",
        "    Basic algorithm: adding the TF frequency of every non-stop word in a sentence divided by total no of words in a sentence.\n",
        "    :rtype: dict\n",
        "    \"\"\"\n",
        "\n",
        "    sentenceValue = {}\n",
        "\n",
        "    for sent, f_table in tf_idf_matrix.items():\n",
        "        total_score_per_sentence = 0\n",
        "\n",
        "        count_words_in_sentence = len(f_table)\n",
        "        for word, score in f_table.items():\n",
        "            total_score_per_sentence += score\n",
        "\n",
        "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
        "\n",
        "    return sentenceValue"
      ],
      "metadata": {
        "id": "2XBlMAailT2j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _find_average_score(sentenceValue) -> int:\n",
        "    \"\"\"\n",
        "    Find the average score from the sentence value dictionary\n",
        "    :rtype: int\n",
        "    \"\"\"\n",
        "    sumValues = 0\n",
        "    for entry in sentenceValue:\n",
        "        sumValues += sentenceValue[entry]\n",
        "\n",
        "    # Average value of a sentence from original summary_text\n",
        "    average = (sumValues / len(sentenceValue))\n",
        "\n",
        "    return average"
      ],
      "metadata": {
        "id": "33vUanh3lY6g"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _generate_summary(sentences, sentenceValue, threshold):\n",
        "    sentence_count = 0\n",
        "    summary = ''\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence[:15] in sentenceValue and sentenceValue[sentence[:15]] >= (threshold):\n",
        "            summary += \" \" + sentence\n",
        "            sentence_count += 1\n",
        "\n",
        "    return summary"
      ],
      "metadata": {
        "id": "bzYs--9vlcwx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "'''\n",
        "We already have a sentence tokenizer, so we just need\n",
        "to run the sent_tokenize() method to create the array of sentences.\n",
        "'''\n",
        "\n",
        "text = input()\n",
        "\n",
        "# 1 Sentence Tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "total_documents = len(sentences)\n",
        "#print(sentences)\n",
        "\n",
        "# 2 Create the Frequency matrix of the words in each sentence.\n",
        "freq_matrix = _create_frequency_matrix(sentences)\n",
        "#print(freq_matrix)\n",
        "\n",
        "'''\n",
        "Term frequency (TF) is how often a word appears in a document, divided by how many words are there in a document.\n",
        "'''\n",
        "# 3 Calculate TermFrequency and generate a matrix\n",
        "tf_matrix = _create_tf_matrix(freq_matrix)\n",
        "#print(tf_matrix)\n",
        "\n",
        "# 4 creating table for documents per words\n",
        "count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
        "#print(count_doc_per_words)\n",
        "\n",
        "'''\n",
        "Inverse document frequency (IDF) is how unique or rare a word is.\n",
        "'''\n",
        "# 5 Calculate IDF and generate a matrix\n",
        "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
        "#print(idf_matrix)\n",
        "\n",
        "# 6 Calculate TF-IDF and generate a matrix\n",
        "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
        "#print(tf_idf_matrix)\n",
        "\n",
        "# 7 Important Algorithm: score the sentences\n",
        "sentence_scores = _score_sentences(tf_idf_matrix)\n",
        "#print(sentence_scores)\n",
        "\n",
        "# 8 Find the threshold\n",
        "threshold = _find_average_score(sentence_scores)\n",
        "#print(threshold)\n",
        "\n",
        "# 9 Important Algorithm: Generate the summary\n",
        "summary = _generate_summary(sentences, sentence_scores, 1.3 * threshold)\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yURDGQpB-KdY",
        "outputId": "11c6045b-5f00-4d1e-e9bc-80e6ab10319f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memek\n",
            " Memek\n"
          ]
        }
      ]
    }
  ]
}